round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
pred.test.mean <- apply(as.data.table(sapply(ls.pred.test, print)), 1, mean)
# submit <- data.table(ID = dt.test$ID, TARGET = pred.test)
submit <- data.table(ID = dt.test$ID, TARGET = pred.test.mean)
write.csv(submit, file = "submission/13_10_xgb_6535_train_valid_cnt0_cnt1_kmeans_benchmark_tuning.csv", row.names = F)
# 0.836426 73 train vs valid
auc(dt.valid$TARGET, pred.valid.mean)
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Santander_Customer_Satisfaction/")
rm(list = ls()); gc();
require(data.table)
require(purrr)
require(caret)
require(xgboost)
require(Ckmeans.1d.dp)
require(Metrics)
require(ggplot2)
require(combinat)
source("utilities/preprocess.R")
source("utilities/cv.R")
load("../data/Santander_Customer_Satisfaction/RData/dt_featureEngineered.RData")
#######################################################################################
## 1.0 train, valid, test #############################################################
#######################################################################################
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.featureEngineered[TARGET >= 0]$TARGET, p = .7, list = F) # remember to change it to .66
dt.train <- dt.featureEngineered[TARGET >= 0][ind.train]
dt.valid <- dt.featureEngineered[TARGET >= 0][-ind.train]
dt.test <- dt.featureEngineered[TARGET == -1]
dim(dt.train); dim(dt.valid); dim(dt.test)
table(dt.train$TARGET)
table(dt.valid$TARGET)
dmx.train <- xgb.DMatrix(data = data.matrix(dt.train[, !c("ID", "TARGET"), with = F]), label = dt.train$TARGET)
dmx.valid <- xgb.DMatrix(data = data.matrix(dt.valid[, !c("ID", "TARGET"), with = F]), label = dt.valid$TARGET)
x.test <- data.matrix(dt.test[, !c("ID", "TARGET"), with = F])
#######################################################################################
## 2.0 train ##########################################################################
#######################################################################################
watchlist <- list(val = dmx.valid, train = dmx.train) # change to dval
params <- list(booster = "gbtree"
, nthread = 8
, objective = "binary:logistic"
, eval_metric = "auc"
, max_depth = 5 # 9
, subsample = .68 #.9
# , min_child_weight = 1
, colsample_bytree = .7 #.5
, eta = .02 #.025
)
round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Santander_Customer_Satisfaction/")
rm(list = ls()); gc();
require(data.table)
require(purrr)
require(caret)
require(xgboost)
require(Ckmeans.1d.dp)
require(Metrics)
require(ggplot2)
require(combinat)
source("utilities/preprocess.R")
source("utilities/cv.R")
load("../data/Santander_Customer_Satisfaction/RData/dt_featureEngineered.RData")
#######################################################################################
## 1.0 train, valid, test #############################################################
#######################################################################################
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.featureEngineered[TARGET >= 0]$TARGET, p = .7, list = F) # remember to change it to .66
dt.train <- dt.featureEngineered[TARGET >= 0][ind.train]
dt.valid <- dt.featureEngineered[TARGET >= 0][-ind.train]
dt.test <- dt.featureEngineered[TARGET == -1]
dim(dt.train); dim(dt.valid); dim(dt.test)
table(dt.train$TARGET)
table(dt.valid$TARGET)
dmx.train <- xgb.DMatrix(data = data.matrix(dt.train[, !c("ID", "TARGET"), with = F]), label = dt.train$TARGET)
dmx.valid <- xgb.DMatrix(data = data.matrix(dt.valid[, !c("ID", "TARGET"), with = F]), label = dt.valid$TARGET)
x.test <- data.matrix(dt.test[, !c("ID", "TARGET"), with = F])
#######################################################################################
## 2.0 train ##########################################################################
#######################################################################################
watchlist <- list(val = dmx.valid, train = dmx.train) # change to dval
params <- list(booster = "gbtree"
, nthread = 8
, objective = "binary:logistic"
, eval_metric = "auc"
, max_depth = 5 # 9
, subsample = .78 #.9
# , min_child_weight = 1
, colsample_bytree = .7 #.5
, eta = .02 #.025
)
round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
pred.test.mean <- apply(as.data.table(sapply(ls.pred.test, print)), 1, mean)
# submit <- data.table(ID = dt.test$ID, TARGET = pred.test)
submit <- data.table(ID = dt.test$ID, TARGET = pred.test.mean)
write.csv(submit, file = "submission/14_10_xgb_73_train_valid_cnt0_cnt1_kmeans_benchmark_tuning_78_ss.csv", row.names = F)
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Santander_Customer_Satisfaction/")
rm(list = ls()); gc();
require(data.table)
require(purrr)
require(caret)
require(xgboost)
require(Ckmeans.1d.dp)
require(Metrics)
require(ggplot2)
require(combinat)
source("utilities/preprocess.R")
source("utilities/cv.R")
load("../data/Santander_Customer_Satisfaction/RData/dt_featureEngineered.RData")
#######################################################################################
## 1.0 train, valid, test #############################################################
#######################################################################################
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.featureEngineered[TARGET >= 0]$TARGET, p = .7, list = F) # remember to change it to .66
dt.train <- dt.featureEngineered[TARGET >= 0][ind.train]
dt.valid <- dt.featureEngineered[TARGET >= 0][-ind.train]
dt.test <- dt.featureEngineered[TARGET == -1]
dim(dt.train); dim(dt.valid); dim(dt.test)
table(dt.train$TARGET)
table(dt.valid$TARGET)
dmx.train <- xgb.DMatrix(data = data.matrix(dt.train[, !c("ID", "TARGET"), with = F]), label = dt.train$TARGET)
dmx.valid <- xgb.DMatrix(data = data.matrix(dt.valid[, !c("ID", "TARGET"), with = F]), label = dt.valid$TARGET)
x.test <- data.matrix(dt.test[, !c("ID", "TARGET"), with = F])
#######################################################################################
## 2.0 train ##########################################################################
#######################################################################################
watchlist <- list(val = dmx.valid, train = dmx.train) # change to dval
params <- list(booster = "gbtree"
, nthread = 8
, objective = "binary:logistic"
, eval_metric = "auc"
, max_depth = 5 # 9
, subsample = .74 #.681
# , min_child_weight = 1
, colsample_bytree = .7 #.5
, eta = .02 #.025
)
round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
pred.test.mean <- apply(as.data.table(sapply(ls.pred.test, print)), 1, mean)
# submit <- data.table(ID = dt.test$ID, TARGET = pred.test)
submit <- data.table(ID = dt.test$ID, TARGET = pred.test.mean)
write.csv(submit, file = "submission/14_10_xgb_73_train_valid_cnt0_cnt1_kmeans_benchmark_tuning_78_ss.csv", row.names = F)
write.csv(submit, file = "submission/15_10_xgb_73_train_valid_cnt0_cnt1_kmeans_benchmark_tuning_74_ss.csv", row.names = F)
file.edit("script/5_imbalance.R")
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Santander_Customer_Satisfaction/")
rm(list = ls()); gc();
require(data.table)
require(purrr)
require(caret)
require(xgboost)
require(Ckmeans.1d.dp)
require(Metrics)
require(ggplot2)
require(combinat)
source("utilities/preprocess.R")
source("utilities/cv.R")
load("../data/Santander_Customer_Satisfaction/RData/dt_featureEngineered.RData")
#######################################################################################
## 1.0 train, valid, test #############################################################
#######################################################################################
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.featureEngineered[TARGET >= 0]$TARGET, p = .7, list = F) # remember to change it to .66
dt.train <- dt.featureEngineered[TARGET >= 0][ind.train]
dt.valid <- dt.featureEngineered[TARGET >= 0][-ind.train]
dt.test <- dt.featureEngineered[TARGET == -1]
dim(dt.train); dim(dt.valid); dim(dt.test)
table(dt.train$TARGET)
table(dt.valid$TARGET)
#######################################################################################
## 2.0 imbalance ######################################################################
#######################################################################################
# UNDER AND OVER SAMPLE
nrow(dt.train[TARGET == 0])
set.seed(888)
sp <- sample(nrow(dt.train[TARGET == 0]), nrow(dt.train[TARGET == 0]) * .5)
length(sp)
dt.train <- rbind(dt.train[TARGET == 0][sp], dt.train[TARGET == 1])
table(dt.train$TARGET)
nrow(dt.train[TARGET == 1])
set.seed(888)
sp <- sample(nrow(dt.train[TARGET == 1]), nrow(dt.train[TARGET == 1]) * .2, replace = T)
length(sp)
dt.train <- rbind(dt.train[TARGET == 1][sp], dt.train[TARGET == 1], dt.train[TARGET == 0])
table(dt.train$TARGET)
#######################################################################################
## 2.0 train ##########################################################################
#######################################################################################
dmx.train <- xgb.DMatrix(data = data.matrix(dt.train[, !c("ID", "TARGET"), with = F]), label = dt.train$TARGET)
dmx.valid <- xgb.DMatrix(data = data.matrix(dt.valid[, !c("ID", "TARGET"), with = F]), label = dt.valid$TARGET)
x.test <- data.matrix(dt.test[, !c("ID", "TARGET"), with = F])
watchlist <- list(val = dmx.valid, train = dmx.train) # change to dval
params <- list(booster = "gbtree"
, nthread = 8
, objective = "binary:logistic"
, eval_metric = "auc"
, max_depth = 5 # 9
, subsample = .74 #.681
# , min_child_weight = 1
, colsample_bytree = .7 #.5
, eta = .02 #.025
)
round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
pred.test.mean <- apply(as.data.table(sapply(ls.pred.test, print)), 1, mean)
# submit <- data.table(ID = dt.test$ID, TARGET = pred.test)
submit <- data.table(ID = dt.test$ID, TARGET = pred.test.mean)
write.csv(submit, file = "submission/16_under_over_sampling_10_xgb_73_train_valid_cnt0_cnt1_kmeans_benchmark_tuning_74_ss.csv", row.names = F)
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Santander_Customer_Satisfaction/")
rm(list = ls()); gc();
require(data.table)
require(purrr)
require(caret)
require(xgboost)
require(Ckmeans.1d.dp)
require(Metrics)
require(ggplot2)
require(combinat)
source("utilities/preprocess.R")
source("utilities/cv.R")
load("../data/Santander_Customer_Satisfaction/RData/dt_featureEngineered.RData")
#######################################################################################
## 1.0 train, valid, test #############################################################
#######################################################################################
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.featureEngineered[TARGET >= 0]$TARGET, p = .7, list = F) # remember to change it to .66
dt.train <- dt.featureEngineered[TARGET >= 0][ind.train]
dt.valid <- dt.featureEngineered[TARGET >= 0][-ind.train]
dt.test <- dt.featureEngineered[TARGET == -1]
dim(dt.train); dim(dt.valid); dim(dt.test)
table(dt.train$TARGET)
table(dt.valid$TARGET)
#######################################################################################
## 2.0 imbalance ######################################################################
#######################################################################################
# UNDER AND OVER SAMPLE
# nrow(dt.train[TARGET == 0])
# set.seed(888)
# sp <- sample(nrow(dt.train[TARGET == 0]), nrow(dt.train[TARGET == 0]) * .5)
# length(sp)
# dt.train <- rbind(dt.train[TARGET == 0][sp], dt.train[TARGET == 1])
# table(dt.train$TARGET)
#
# nrow(dt.train[TARGET == 1])
# set.seed(888)
# sp <- sample(nrow(dt.train[TARGET == 1]), nrow(dt.train[TARGET == 1]) * .2, replace = T)
# length(sp)
# dt.train <- rbind(dt.train[TARGET == 1][sp], dt.train[TARGET == 1], dt.train[TARGET == 0])
# table(dt.train$TARGET)
# UNDER SAMPLE
nrow(dt.train[TARGET == 0])
set.seed(888)
sp <- sample(nrow(dt.train[TARGET == 0]), nrow(dt.train[TARGET == 0]) * .7)
length(sp)
dt.train <- rbind(dt.train[TARGET == 0][sp], dt.train[TARGET == 1])
table(dt.train$TARGET)
#######################################################################################
## 2.0 train ##########################################################################
#######################################################################################
dmx.train <- xgb.DMatrix(data = data.matrix(dt.train[, !c("ID", "TARGET"), with = F]), label = dt.train$TARGET)
dmx.valid <- xgb.DMatrix(data = data.matrix(dt.valid[, !c("ID", "TARGET"), with = F]), label = dt.valid$TARGET)
x.test <- data.matrix(dt.test[, !c("ID", "TARGET"), with = F])
watchlist <- list(val = dmx.valid, train = dmx.train) # change to dval
params <- list(booster = "gbtree"
, nthread = 8
, objective = "binary:logistic"
, eval_metric = "auc"
, max_depth = 5 # 9
, subsample = .74 #.681
# , min_child_weight = 1
, colsample_bytree = .7 #.5
, eta = .02 #.025
)
round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
pred.test.mean <- apply(as.data.table(sapply(ls.pred.test, print)), 1, mean)
# submit <- data.table(ID = dt.test$ID, TARGET = pred.test)
submit <- data.table(ID = dt.test$ID, TARGET = pred.test.mean)
write.csv(submit, file = "submission/17_under_sampling_10_xgb_73_train_valid_cnt0_cnt1_kmeans_benchmark_tuning_74_ss.csv", row.names = F)
setwd("/Volumes/Data Science/Google Drive/data_science_competition/kaggle/Santander_Customer_Satisfaction/")
rm(list = ls()); gc();
require(data.table)
require(purrr)
require(caret)
require(xgboost)
require(Ckmeans.1d.dp)
require(Metrics)
require(ggplot2)
require(combinat)
source("utilities/preprocess.R")
source("utilities/cv.R")
load("../data/Santander_Customer_Satisfaction/RData/dt_featureEngineered.RData")
#######################################################################################
## 1.0 train, valid, test #############################################################
#######################################################################################
cat("prepare train, valid, and test data set...\n")
set.seed(888)
ind.train <- createDataPartition(dt.featureEngineered[TARGET >= 0]$TARGET, p = .7, list = F) # remember to change it to .66
dt.train <- dt.featureEngineered[TARGET >= 0][ind.train]
dt.valid <- dt.featureEngineered[TARGET >= 0][-ind.train]
dt.test <- dt.featureEngineered[TARGET == -1]
dim(dt.train); dim(dt.valid); dim(dt.test)
table(dt.train$TARGET)
table(dt.valid$TARGET)
#######################################################################################
## 2.0 imbalance ######################################################################
#######################################################################################
# UNDER AND OVER SAMPLE
# nrow(dt.train[TARGET == 0])
# set.seed(888)
# sp <- sample(nrow(dt.train[TARGET == 0]), nrow(dt.train[TARGET == 0]) * .5)
# length(sp)
# dt.train <- rbind(dt.train[TARGET == 0][sp], dt.train[TARGET == 1])
# table(dt.train$TARGET)
#
# nrow(dt.train[TARGET == 1])
# set.seed(888)
# sp <- sample(nrow(dt.train[TARGET == 1]), nrow(dt.train[TARGET == 1]) * .2, replace = T)
# length(sp)
# dt.train <- rbind(dt.train[TARGET == 1][sp], dt.train[TARGET == 1], dt.train[TARGET == 0])
# table(dt.train$TARGET)
# UNDER SAMPLE
# nrow(dt.train[TARGET == 0])
# set.seed(888)
# sp <- sample(nrow(dt.train[TARGET == 0]), nrow(dt.train[TARGET == 0]) * .7)
# length(sp)
# dt.train <- rbind(dt.train[TARGET == 0][sp], dt.train[TARGET == 1])
# table(dt.train$TARGET)
# OVER SAMPLE
nrow(dt.train[TARGET == 1])
set.seed(888)
sp <- sample(nrow(dt.train[TARGET == 1]), nrow(dt.train[TARGET == 1]) * .1, replace = T)
length(sp)
dt.train <- rbind(dt.train[TARGET == 1][sp], dt.train[TARGET == 1], dt.train[TARGET == 0])
table(dt.train$TARGET)
#######################################################################################
## 2.0 train ##########################################################################
#######################################################################################
dmx.train <- xgb.DMatrix(data = data.matrix(dt.train[, !c("ID", "TARGET"), with = F]), label = dt.train$TARGET)
dmx.valid <- xgb.DMatrix(data = data.matrix(dt.valid[, !c("ID", "TARGET"), with = F]), label = dt.valid$TARGET)
x.test <- data.matrix(dt.test[, !c("ID", "TARGET"), with = F])
watchlist <- list(val = dmx.valid, train = dmx.train) # change to dval
params <- list(booster = "gbtree"
, nthread = 8
, objective = "binary:logistic"
, eval_metric = "auc"
, max_depth = 5 # 9
, subsample = .74 #.681
# , min_child_weight = 1
, colsample_bytree = .7 #.5
, eta = .02 #.025
)
round <- 10
ls.pred.valid <- list()
ls.pred.test <- list()
for(i in 1:round){
set.seed(1234 * i)
md.xgb <- xgb.train(params = params
, data = dmx.train
, nrounds = 100000
, early.stop.round = 50
, watchlist = watchlist
, print.every.n = 50
, verbose = F
)
# valid
pred.valid <- predict(md.xgb, dmx.valid)
ls.pred.valid[[i]] <- pred.valid
print(paste("round:", i, "valid auc:", auc(dt.valid$TARGET, pred.valid)))
# test
pred.test <- predict(md.xgb, x.test)
ls.pred.test[[i]] <- pred.test
}
pred.valid.mean <- apply(as.data.table(sapply(ls.pred.valid, print)), 1, mean)
auc(dt.valid$TARGET, pred.valid.mean)
pred.test.mean <- apply(as.data.table(sapply(ls.pred.test, print)), 1, mean)
# submit <- data.table(ID = dt.test$ID, TARGET = pred.test)
submit <- data.table(ID = dt.test$ID, TARGET = pred.test.mean)
write.csv(submit, file = "submission/18_over_sampling_10_xgb_73_train_valid_cnt0_cnt1_kmeans_benchmark_tuning_74_ss.csv", row.names = F)
